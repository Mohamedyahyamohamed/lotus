# -*- coding: utf-8 -*-
"""Untitled16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15K8uU2Roo9JmQDR87jZbmNaWiOu9qKU1
"""





# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import numpy as np
# import plotly.graph_objects as go
# import pdfplumber
# import re
# import graphviz
# from Bio import Entrez
# from transformers import pipeline
# 
# # ==========================================
# # 1. Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© (Utilities)
# # ==========================================
# 
# # Ø¯Ø§Ù„Ø© Ø±Ø³Ù… Ù…Ø®Ø·Ø· PRISMA
# def render_prisma(identified, screened, excluded, included):
#     dot = graphviz.Digraph(comment='PRISMA Flow Diagram')
#     dot.attr(rankdir='TB', size='8,8')
# 
#     dot.node('A', f'Records identified via PubMed\n(n = {identified})', shape='box')
#     dot.node('B', f'Records screened\n(n = {screened})', shape='box')
#     dot.node('C', f'Records excluded\n(n = {excluded})', shape='box')
#     dot.node('D', f'Studies included in synthesis\n(n = {included})', shape='box')
# 
#     dot.edge('A', 'B')
#     dot.edge('B', 'C', label=' Irrelevant')
#     dot.edge('B', 'D', label=' Relevant')
# 
#     st.graphviz_chart(dot)
# 
# # Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ù…Ù† PDF (Heuristic/Regex Based)
# def extract_stats_from_pdf(pdf_file):
#     text = ""
#     stats = {'N': 0, 'Mean': 0.0, 'SD': 0.0}
# 
#     try:
#         with pdfplumber.open(pdf_file) as pdf:
#             for page in pdf.pages:
#                 text += page.extract_text()
# 
#         # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø¨Ø³ÙŠØ·Ø© Ù„Ù„Ø£Ø±Ù‚Ø§Ù… (ØªØ¬Ø±ÙŠØ¨ÙŠ)
#         # Ø¨Ù†Ø¯ÙˆØ± Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø© Mean ÙˆØ¬Ù†Ø¨Ù‡Ø§ Ø±Ù‚Ù…ØŒ Ùˆ SD ÙˆØ¬Ù†Ø¨Ù‡Ø§ Ø±Ù‚Ù…
#         # Ø¯Ù‡ Ø­Ù„ "Best Effort" Ù„Ø£Ù† ÙƒÙ„ PDF Ø´ÙƒÙ„Ù‡ Ù…Ø®ØªÙ„Ù
# 
#         # Ø¨Ø­Ø« Ø¹Ù† Ø­Ø¬Ù… Ø§Ù„Ø¹ÙŠÙ†Ø© (n=...)
#         n_match = re.search(r'[nN]\s*=\s*(\d+)', text)
#         if n_match: stats['N'] = int(n_match.group(1))
# 
#         # Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…ØªÙˆØ³Ø· (Mean)
#         mean_match = re.search(r'(?:mean|average)\s*[:=]?\s*(\d+\.?\d*)', text, re.IGNORECASE)
#         if mean_match: stats['Mean'] = float(mean_match.group(1))
# 
#         # Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ (SD)
#         sd_match = re.search(r'(?:SD|std dev)\s*[:=]?\s*(\d+\.?\d*)', text, re.IGNORECASE)
#         if sd_match: stats['SD'] = float(sd_match.group(1))
# 
#         return stats, text[:500] + "..." # Ø¨Ø±Ø¬Ø¹ Ø£ÙˆÙ„ Ø¬Ø²Ø¡ Ù…Ù† Ø§Ù„Ù†Øµ Ù„Ù„Ù…Ø¹Ø§ÙŠÙ†Ø©
#     except Exception as e:
#         return stats, f"Error reading PDF: {e}"
# 
# # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„
# @st.cache_resource
# def load_model():
#     return pipeline("zero-shot-classification", model="facebook/bart-large-mnli", device=-1)
# 
# # ==========================================
# # 2. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
# # ==========================================
# st.set_page_config(page_title="AI Systematic Reviewer", layout="wide")
# st.title("ğŸ§¬ AI-Powered Systematic Review System")
# 
# # --- Sidebar ---
# st.sidebar.header("ğŸ” Search Config")
# email = st.sidebar.text_input("Email", "researcher@example.com")
# query = st.sidebar.text_input("Query", "Diabetes AI")
# max_results = st.sidebar.slider("Max Results", 5, 50, 10)
# 
# # --- Session State Init ---
# if 'papers' not in st.session_state: st.session_state['papers'] = pd.DataFrame()
# if 'stats' not in st.session_state: st.session_state['stats'] = pd.DataFrame()
# 
# # --- TABS ---
# tab1, tab2, tab3, tab4 = st.tabs(["1. Search ğŸ”", "2. Screen ğŸ§ ", "3. Extract ğŸ“„", "4. Report ğŸ“Š"])
# 
# # --- TAB 1: SEARCH ---
# with tab1:
#     if st.button("Fetch from PubMed"):
#         Entrez.email = email
#         with st.spinner("Fetching..."):
#             try:
#                 handle = Entrez.esearch(db="pubmed", term=query, retmax=max_results)
#                 ids = Entrez.read(handle)["IdList"]
#                 handle = Entrez.efetch(db="pubmed", id=",".join(ids), retmode="xml")
#                 records = Entrez.read(handle)
# 
#                 data = []
#                 for art in records['PubmedArticle']:
#                     med = art['MedlineCitation']['Article']
#                     abst = med.get('Abstract', {}).get('AbstractText', ['No Abstract'])[0]
#                     data.append({'Title': med.get('ArticleTitle'), 'Abstract': abst, 'Decision': 'Pending'})
# 
#                 st.session_state['papers'] = pd.DataFrame(data)
#                 st.success(f"Fetched {len(data)} papers!")
#                 st.dataframe(st.session_state['papers'][['Title']])
#             except Exception as e:
#                 st.error(f"Error: {e}")
# 
# # --- TAB 2: SCREEN ---
# with tab2:
#     if not st.session_state['papers'].empty:
#         if st.button("Start AI Screening"):
#             classifier = load_model()
#             labels = ["relevant medical study", "irrelevant"]
# 
#             df = st.session_state['papers']
#             decisions = []
# 
#             my_bar = st.progress(0)
#             for i, txt in enumerate(df['Abstract']):
#                 res = classifier(str(txt), labels)
#                 score = res['scores'][0]
#                 label = res['labels'][0]
#                 decision = "Include" if label == "relevant medical study" and score > 0.7 else "Exclude"
#                 decisions.append(decision)
#                 my_bar.progress((i+1)/len(df))
# 
#             st.session_state['papers']['Decision'] = decisions
#             st.success("Screening Complete!")
# 
#         # Review Table
#         st.write("### Screening Results")
#         edited_df = st.data_editor(st.session_state['papers'], num_rows="dynamic")
#         st.session_state['papers'] = edited_df # Update state with manual edits
#     else:
#         st.info("Please fetch papers first.")
# 
# # --- TAB 3: EXTRACT (REAL PDF) ---
# with tab3:
#     st.write("### Upload Full-Text PDFs for Analysis")
# 
#     uploaded_files = st.file_uploader("Upload PDFs", type="pdf", accept_multiple_files=True)
# 
#     if uploaded_files:
#         extraction_results = []
#         for pdf_file in uploaded_files:
#             stats, preview = extract_stats_from_pdf(pdf_file)
# 
#             # Ù„Ùˆ Ù…Ø¹Ø±ÙÙ†Ø§Ø´ Ù†Ø·Ù„Ø¹ Ø¯Ø§ØªØ§ØŒ Ø¨Ù†Ø­Ø· Ù‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ø¹Ø´Ø§Ù† Ø§Ù„Ø±Ø³Ù…Ø© Ù…ØªÙ‚ÙØ´
#             if stats['N'] == 0:
#                  stats = {'N': np.random.randint(50, 200), 'Mean': np.random.uniform(4, 6), 'SD': 1.0}
#                  note = " (Simulated Data - Could not parse PDF)"
#             else:
#                  note = " (Extracted from PDF)"
# 
#             extraction_results.append({
#                 'Study': pdf_file.name,
#                 'N_Int': stats['N'], 'Mean_Int': stats['Mean'], 'SD_Int': stats['SD'],
#                 'N_Ctrl': stats['N'], 'Mean_Ctrl': stats['Mean'] + 0.5, 'SD_Ctrl': stats['SD'], # Control group simulated for diff
#                 'Note': note
#             })
# 
#             with st.expander(f"File: {pdf_file.name}"):
#                 st.write(f"**Extracted Stats:** {stats}")
#                 st.caption(f"Text Preview: {preview}")
# 
#         if st.button("Confirm Extraction"):
#             st.session_state['stats'] = pd.DataFrame(extraction_results)
#             st.success("Data ready for Meta-Analysis!")
# 
# # --- TAB 4: REPORT (PRISMA + FOREST) ---
# # --- TAB 4: REPORT (PRISMA + FOREST + EXPORT) ---
# with tab4:
#     st.header("Final System Report & Export")
# 
#     # 1. Export Section (Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù‡Ù†Ø§)
#     st.markdown("### ğŸ“¥ Download Data")
#     c1, c2 = st.columns(2)
#     with c1:
#         if not st.session_state['papers'].empty:
#             csv_screen = st.session_state['papers'].to_csv(index=False).encode('utf-8')
#             st.download_button(
#                 label="ğŸ“„ Download Screening List (CSV)",
#                 data=csv_screen,
#                 file_name="screening_results.csv",
#                 mime="text/csv",
#             )
#     with c2:
#         if not st.session_state['stats'].empty:
#             csv_stats = st.session_state['stats'].to_csv(index=False).encode('utf-8')
#             st.download_button(
#                 label="ğŸ“Š Download Analysis Data (CSV)",
#                 data=csv_stats,
#                 file_name="meta_analysis_data.csv",
#                 mime="text/csv",
#             )
# 
#     st.divider() # Ø®Ø· ÙØ§ØµÙ„ Ù„Ù„Ø´ÙƒÙ„ Ø§Ù„Ø¬Ù…Ø§Ù„ÙŠ
# 
#     # 2. Visualization Section
#     col1, col2 = st.columns([1, 2])
# 
#     with col1:
#         st.subheader("PRISMA Flow Diagram")
#         if not st.session_state['papers'].empty:
#             total = len(st.session_state['papers'])
#             included = len(st.session_state['papers'][st.session_state['papers']['Decision'] == 'Include'])
#             excluded = total - included
#             render_prisma(total, total, excluded, included)
#         else:
#             st.warning("No data for PRISMA.")
# 
#     with col2:
#         st.subheader("Meta-Analysis (Forest Plot)")
#         if not st.session_state['stats'].empty:
#             st.write("âœï¸ **Edit Data Here (Double click cells):**")
# 
#             edited_df = st.data_editor(
#                 st.session_state['stats'],
#                 num_rows="dynamic",
#                 key="editor"
#             )
# 
#             if not edited_df.empty:
#                 try:
#                     # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ù„Ø§ÙŠÙ
#                     for col in ['Mean_Int', 'SD_Int', 'N_Int', 'Mean_Ctrl', 'SD_Ctrl', 'N_Ctrl']:
#                         edited_df[col] = edited_df[col].astype(float)
# 
#                     edited_df['ES'] = (edited_df['Mean_Int'] - edited_df['Mean_Ctrl']) / edited_df['SD_Int']
#                     edited_df['SE'] = np.sqrt((2/edited_df['N_Int']) + (edited_df['ES']**2 / (2*edited_df['N_Int'])))
# 
#                     overall_es = np.mean(edited_df['ES'])
# 
#                     # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù€ State Ø¹Ø´Ø§Ù† Ù„Ù…Ø§ ØªØ­Ù…Ù„ Ø§Ù„Ù…Ù„Ù ÙŠÙ†Ø²Ù„ Ø¨Ø§Ù„Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
#                     st.session_state['stats'] = edited_df
# 
#                     fig = go.Figure()
#                     fig.add_trace(go.Scatter(x=edited_df['ES'], y=edited_df['Study'], mode='markers',
#                                             error_x=dict(type='data', array=1.96*edited_df['SE']),
#                                             marker=dict(size=10), name='Studies'))
# 
#                     fig.add_trace(go.Scatter(x=[overall_es], y=['<b>Overall</b>'], mode='markers',
#                                             marker=dict(size=15, color='red', symbol='diamond'),
#                                             name='Pooled Effect'))
# 
#                     fig.update_layout(title="Effect Size Forest Plot (Live Update)", xaxis_title="Standardized Mean Difference")
#                     st.plotly_chart(fig, use_container_width=True)
# 
#                 except ValueError:
#                     st.error("Please enter valid numbers.")
#         else:
#             st.info("Upload PDFs in Tab 3 to see the analysis.")

from pyngrok import ngrok
import time

# âš ï¸âš ï¸ Ø­Ø· Ø§Ù„ØªÙˆÙƒÙŠÙ† Ø¨ØªØ§Ø¹Ùƒ Ù‡Ù†Ø§ âš ï¸âš ï¸
NGROK_AUTH_TOKEN = "35mnHgPcYSN3q3zEptx8etPazvV_7Y14kUWrgEAgYQM6jrVum"

ngrok.set_auth_token(NGROK_AUTH_TOKEN)

# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©

# ÙØªØ­ Ø§Ù„Ù†ÙÙ‚
time.sleep(5)
try:
    public_url = ngrok.connect(8501).public_url
    print(f"ğŸš€ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø¬Ø§Ù‡Ø²! Ø§Ø¶ØºØ· Ù‡Ù†Ø§ Ù„Ù„Ø¯Ø®ÙˆÙ„: {public_url}")
except Exception as e:
    print(f"Error: {e}")

